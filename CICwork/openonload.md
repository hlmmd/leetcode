# Openonload

## 背景介绍

### 简介

Onload是Solarflare加速网络中间件。它基于TCP/UDP/IP实现，动态链接到用户模式应用程序的地址空间，并授予对网络适配器硬件的直接（但安全）访问。这样数据可以直接由应用程序传输到网络和从网络接收，而无需操作系统的参与。 这种技术称为“kernel bypass”。

kernel bypass避免了系统调用，上下文切换和中断等事件，从而提高了处理器执行应用程序代码的效率。这也直接减少了主机处理开销\(通常减少了两倍\)，从而为应用程序处理留下了更多的CPU时间。对于网络密集型应用程序效果更为明显。

Onload库使用标准BSD套接字API在运行时动态链接应用程序，这意味着不需要对需要加速的应用程序进行任何修改。 Onload是第一个也是唯一一个通过TCP / IP和UDP / IP协议为基于POSIX套接字的应用程序提供完全kernel bypass的产品。

### 与传统网络的对比

当使用传统网络时，应用程序调用OS内核以向网络发送数据和从网络接收数据。 从应用程序转换到内核是一项高代价的操作，是影响性能的一大障碍。

当使用Onload加速的应用程序需要发送或接收数据时，它不需要访问操作系统内核，就可以直接访问网络适配器上的分区。

![](.gitbook/assets/image.png)

传统模型的一个重要特征是应用程序无法直接访问网络硬件，因此不会影响系统完整性。 Onload能够通过将硬件级别的NIC划分为许多受保护的“虚拟NIC”（VNIC）来保持系统完整性。可以授予应用程序直接访问VNIC而无法访问系统的其余部分（包括其他VNIC或不属于该应用程序的内存）。 因此，使用Solarflare NIC的Onload可在不影响安全性或系统完整性的情况下实现最佳性能。

总的来说，Onload能够有效地减少网络处理开销。

### Onload优势

通过降低CPU开销，降低延迟，提升带宽和可伸缩性的性能，Onload可以显着降低与网络相关的成本。

### 开销

从用户空间应用程序转入和转出内核是一项高开销的操作：相当于数百或数千条指令。对于传统网络，每次应用程序发送和接收数据时都需要进行转换。

使用Onload，TCP / IP处理可以完全在用户进程内完成，从而消除了应用程序/内核转换，即系统调用。此外，Onload TCP / IP堆栈经过高度调整，可进一步节省开销。 Onload的开销节省意味着更多的CPU计算能力可供应用程序执行有用的工作。

### 延迟

传统网络应用中，当服务器应用程序准备好处理事务时，它调用OS内核来执行“接收”操作，其中内核将调用线程“休眠”直到请求从网络到达。当这样的请求到达时，网络硬件“中断”内核，内核接收请求并“唤醒”应用程序。所有这些开销都需要CPU周期以及增加缓存和转换后备缓冲区（TLB）占用空间。

使用Onload，应用程序可以保持在用户态，等待请求到达网络适配器并直接处理它们。消除内核态和用户态的转换、中断以及用户态到内核态的转换，这样可以显着减少延迟。简而言之，降低的开销意味着减少延迟。

### 带宽 

因为Onload减少了开销，所以它可以每秒处理更多字节的网络流量。除了针对10千兆位网络设计的专门调整的缓冲和算法外，Onload还允许应用程序显着提高带宽。

### 可扩展性

现代多核系统能够同时运行许多应用程序。但是，当多个内核竞争单个资源（例如内核网络堆栈或设备驱动程序中的锁定）时，优势很快就会丢失。在具有跨多个CPU内核和非统一内存架构的多个高速缓存的现代系统中，这些问题更加复杂。

Onload将网络适配器分区，并且每个分区都由TCP / IP堆栈的独立副本访问。 所以使用Onload，加倍核心的数量就可以加倍吞吐量

![](.gitbook/assets/image%20%284%29.png)

## Onload功能

### 透明性

Onload无需重写或重新编译用户应用程序就能显着改进程序的性能，同时保持与标准TCP和UDP协议的完全互操作性。 在常规内核TCP / IP体系结构中，应用程序动态链接到libc库。该OS库通过一组“包装器”函数提供对标准BSD套接字API的支持，并在内核级别进行实际处理。 Onload还支持标准BSD套接字API。但是，与内核TCP / IP相比，Onload将协议处理移出内核空间并进入用户级Onload库本身。 网络应用程序调用标准套接字API函数调用，例如socket（），read（），write（）等，它们由Onload库拦截，利用Linux上的LD\_PRELOAD机制。在每个函数调用中，Onload将使用Solarflare接口检查套接字的文件描述符 - 这些接口由Onload堆栈处理，而不使用Solarflare接口的则传递给内核堆栈。

### Onload堆栈

Onload stack是TCP / IP堆栈的实例。 该堆栈包括发送和接收缓冲区，开放连接以及相关的端口号和堆栈选项。 每个堆栈都与一个或多个虚拟NIC关联（通常每个堆栈正在使用的物理端口一个）。 在正常使用中，每个进程都将拥有自己的Onload堆栈，该堆栈被该进程创建的所有连接共享。 多个进程也可以共享单个Onload堆栈实例，单个应用程序可以共享多个Onload堆栈。 

### 虚拟网络接口控制器（V-NIC）

Solarflare网络适配器支持1024个传输队列，1024个接收队列，1024个事件队列和每个网络端口1024个计时器资源。 VNIC（虚拟网络接口）由这些资源中的每一个实例组成，其允许Onload栈，以一种隔离且安全的方式来发送和接收网络流量。 通过网络适配器和/或接收侧缩放（RSS）上的IP / MAC过滤器表将接收的数据包引导至正确的VNIC。 Onload堆栈为每个Solarflare网络端口分配一个VNIC，因此它具有来自用户模式的专用发送和接收通道。 重置Solarflare网络适配器驱动程序后，将重新安装所有虚拟接口资源，包括Onload堆栈和套接字。 重置操作对应用程序是透明的，但在重置期间流量将丢失。

### 功能概述

在建立第一个套接字时，会为应用程序分配一个Onload堆栈，该堆栈分配所需的VNIC。

当数据包到达时，适配器中的IP过滤标识套接字，并将数据写入相应Onload堆栈中的下一个可用接收缓冲区。 然后，适配器将事件写入由Onload管理的“事件队列”。 如果应用程序定期进行套接字调用，则Onload会定期轮询此事件队列，然后直接处理事件而不是产生中断。

用户态处理显着降低了内核/用户态上下文切换造成的开销，只有应用程序阻塞时才会产生中断。

### Onload与多网络适配器

### 最大网络接口数量

Onload驱动最多支持32个网络接口。默认每个Onload堆栈支持8个接口（可提升到16个）

### 接口白/黑名单

### Onloaded PIDs

能直接查询使用Onload加速的进程PID

onload\_fuser -v

### Control Plane Server

### IO复用

select\(\)、poll\(\)、epoll\(\)

### Stack共享

### 应用程序集群

## Onload - TCP

### TCP RFC规范

![](.gitbook/assets/image%20%282%29.png)

### TCP 三次握手



## 限制

### 简介

本章介绍Onload无法加速或者会改变系统和应用行为的情况。Onload一个关键点是要与常规的内核堆栈完全兼容，但在某些情况下行为会发生偏差。

### 资源

Onload使用网络适配器上的某些物理资源。如果这些资源耗尽，则无法创建新的Onload堆栈，也无法加速新的套接字或应用程序。应使用onload\_stackdump实用程序来监视硬件资源。物理资源包括：

#### V-NICs

虚拟NIC提供用户级应用程序通过其发送和接收网络流量的接口。当这些耗尽时，无法创建新的Onload堆栈，这意味着无法加速新的应用程序。但是，Solarflare网络适配器支持大量虚拟NIC，并且此资源通常不是第一个不可用的资源。

#### Endpoints

Onload将套接字和管道表示为称为Endpoints的结构。每个Onload堆栈允许的最大加速端点数使用EF\_MAX\_ENDPOINTS变量设置。

#### Filters

过滤器用于将从线路接收的数据包传送到适当的应用程序。当过滤器耗尽时，无法创建新的加速套接字。一般建议是应用程序不会分配超过4096个过滤器 - 或者应用程序不应创建超过4096个传出连接。 该限制不适用于侦听套接字的入站连接。

#### Buffer Table

缓冲表为DMA缓冲区提供地址保护和转换。当所有缓冲区资源都耗尽时，无法创建新的Onload堆栈，并且现有堆栈无法分配更多DMA缓冲区。

当硬件资源耗尽时，系统的正常操作应该继续，但是不可能加速新的套接字或应用程序。

#### TX, RX Ring Buffer Size

Onload不服从内核中设置的RX，TX环大小，而是使用EF\_RXQ\_SIZE和EF\_TXQ\_SIZE指定的值，默认为512。

### 操作限制

#### 关闭多线程应用

由于Onload在调用应用程序的线程的上下文中处理网络，因此建议应用程序确保在进程终止时所有线程都干净地退出。 特别是exit（）函数会导致所有线程立即退出 - 即使是关键部分中的线程也是如此。 这可能导致当前位于Onload堆栈中的线程保持每堆栈锁定而不释放此共享锁 - 这对于共享堆栈尤其重要，在共享堆栈中，当未释放Onload锁时，共享堆栈的进程可能会“挂起”。

#### 抓包

tcpdump、wireshark无法获取onload的包，需使用onload\_tcpdump。

#### 防火墙、信号、线程安全、socket shundown

### 加速限制

#### IP分片

接收端的Onload不会加速IP分片流量，而是通过内核堆栈透明地接收。 TCP很少出现IP分片，因为TCP / IP堆栈将消息分段为MTU大小的IP数据报。 对于UDP，如果数据报对于配置的MTU来说太大，则会对其进行分片。

#### 广播传输

#### IPv6

……

















































